{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Bag of words features for app ids, phone brand and device models.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries have been loaded\n"
     ]
    }
   ],
   "source": [
    "__imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Additional Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import scipy as sp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import log_loss\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.preprocessing import scale\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/ml/talking_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 238 ms, sys: 200 ms, total: 438 ms\n",
      "Wall time: 437 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gender_age_train         = pd.read_feather(os.path.join(basepath, 'data/processed/gender_age_train.feather'))\n",
    "gender_age_test          = pd.read_feather(os.path.join(basepath, 'data/processed/gender_age_test.feather'))\n",
    "phone_brand_device_model = pd.read_feather(os.path.join(basepath, 'data/processed/phone_brand_device_model.feather')) \n",
    "app_events               = pd.read_feather(os.path.join(basepath, 'data/processed/app_events.feather'))\n",
    "events                   = pd.read_feather(os.path.join(basepath, 'data/processed/events.feather'))\n",
    "\n",
    "phone_brand_device_model = phone_brand_device_model.drop_duplicates()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(train):\n",
    "    dtr, dte, _, _ = train_test_split(train, \n",
    "                                      train.group, \n",
    "                                      stratify=train.group,\n",
    "                                      test_size=.2\n",
    "                                     )\n",
    "    \n",
    "    dtr, dval, _, _ = train_test_split(dte, dte.group,\n",
    "                                       stratify=dte.group,\n",
    "                                       test_size=.2\n",
    "                                      )\n",
    "    \n",
    "    del dte\n",
    "    gc.collect()\n",
    "    \n",
    "    return dtr, dval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train     = gender_age_train.merge(phone_brand_device_model, on='device_id', how='left')\n",
    "dtr, dval = get_train_test(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M23-26    0.128600\n",
       "M32-38    0.126926\n",
       "M39+      0.114869\n",
       "M22-      0.100469\n",
       "M29-31    0.097790\n",
       "F33-42    0.074347\n",
       "M27-28    0.073007\n",
       "F23-      0.067649\n",
       "F29-32    0.061956\n",
       "F43+      0.056263\n",
       "F24-26    0.056263\n",
       "F27-28    0.041862\n",
       "Name: group, dtype: float64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dval.group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M23-26    0.128684\n",
       "M32-38    0.126926\n",
       "M39+      0.114953\n",
       "M22-      0.100301\n",
       "M29-31    0.097957\n",
       "F33-42    0.074514\n",
       "M27-28    0.072924\n",
       "F23-      0.067649\n",
       "F29-32    0.062040\n",
       "F43+      0.056179\n",
       "F24-26    0.056095\n",
       "F27-28    0.041778\n",
       "Name: group, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.03775805196249212\n",
      "Validation: 0.03938986953184958\n"
     ]
    }
   ],
   "source": [
    "# check number of device with no events in training and test set\n",
    "_ = dtr.merge(events, on='device_id', how='left')\n",
    "print('Train: {}'.format(_[_.event_id.isnull()].shape[0] / len(_)))\n",
    "\n",
    "_ = dval.merge(events, on='device_id', how='left')\n",
    "print('Validation: {}'.format(_[_.event_id.isnull()].shape[0] / len(_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for brand names\n",
    "chinese_to_eng_brands = {\n",
    "'三星'   : 'samsung',\n",
    "'天语'   : 'Ktouch',\n",
    "'海信'   : 'hisense',\n",
    "'联想'   : 'lenovo',\n",
    "'欧比'   : 'obi',\n",
    "'爱派尔' : 'ipair',\n",
    "'努比亚' : 'nubia',\n",
    "'优米'   : 'youmi',\n",
    "'朵唯'   : 'dowe',\n",
    "'黑米'   : 'heymi',\n",
    "'锤子'   : 'hammer',\n",
    "'酷比魔方': 'koobee',\n",
    "'美图'   : 'meitu',\n",
    "'尼比鲁' : 'nibilu',\n",
    "'一加'   : 'oneplus',\n",
    "'优购': 'yougo',\n",
    "'诺基亚': 'nokia',\n",
    "'糖葫芦': 'candy',\n",
    "'中国移动':'ccmc',\n",
    "'语信': 'yuxin',\n",
    "'基伍': 'kiwu',\n",
    "'青橙': 'greeno',\n",
    "'华硕': 'asus',\n",
    "'夏新': 'panosonic',\n",
    "'维图': 'weitu',\n",
    "'艾优尼': 'aiyouni',\n",
    "'摩托罗拉': 'moto',\n",
    "'乡米': 'xiangmi',\n",
    "'米奇': 'micky',\n",
    "'大可乐': 'bigcola',\n",
    "'沃普丰': 'wpf',\n",
    "'神舟': 'hasse',\n",
    "'摩乐': 'mole',\n",
    "'飞秒': 'fs',\n",
    "'米歌': 'mige',\n",
    "'富可视': 'fks',\n",
    "'德赛': 'desci',\n",
    "'梦米': 'mengmi',\n",
    "'乐视': 'lshi',\n",
    "'小杨树':'smallt',\n",
    "'纽曼': 'newman',\n",
    "'邦华' : 'banghua',\n",
    "'E派' : 'epai',\n",
    "'易派': 'epai',\n",
    "'普耐尔': 'pner',\n",
    "'欧新': 'ouxin',\n",
    "'西米': 'ximi',\n",
    "'海尔': 'haier',\n",
    "'波导': 'bodao',\n",
    "'糯米': 'nuomi',\n",
    "'唯米': 'weimi',\n",
    "'酷珀': 'kupo',\n",
    "'谷歌': 'google',\n",
    "'昂达': 'ada',\n",
    "'聆韵': 'lingyun',\n",
    "'华为': 'Huawei',\n",
    "'小米': 'millet',\n",
    "'魅族': 'Meizu',\n",
    "'金立': 'Gionee'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate models for devices with no events versus devices with events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 871 ms, sys: 112 ms, total: 983 ms\n",
      "Wall time: 985 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "dtr_events   = dtr.merge(events, on='device_id', how='left')\\\n",
    "                  .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "    \n",
    "dval_events  = dval.merge(events, on='device_id', how='left')\\\n",
    "                   .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "\n",
    "# devices in training set\n",
    "tr_devices_with_events    = dtr_events.loc[dtr_events.event_id.notnull(), 'device_id']\n",
    "tr_devices_with_no_events = dtr_events.loc[dtr_events.event_id.isnull(), 'device_id']\n",
    "\n",
    "# devices in validation set\n",
    "val_devices_with_events    = dval_events.loc[dval_events.event_id.notnull(), 'device_id']\n",
    "val_devices_with_no_events = dval_events.loc[dval_events.event_id.isnull(), 'device_id'] \n",
    "\n",
    "# separate out training set based on whether events were generated by a device or not\n",
    "tr_no_events = dtr.loc[dtr.device_id.isin(tr_devices_with_no_events), :]\n",
    "tr_events    = dtr.loc[dtr.device_id.isin(tr_devices_with_events), :]\n",
    "\n",
    "tr_no_events.loc[:, 'phone_brand'] = tr_no_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "tr_events.loc[:, 'phone_brand']    = tr_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "\n",
    "\n",
    "te_no_events = dval.loc[dval.device_id.isin(val_devices_with_no_events), :]\n",
    "te_events    = dval.loc[dval.device_id.isin(val_devices_with_events), :]\n",
    "\n",
    "te_no_events.loc[:, 'phone_brand'] = te_no_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "te_events.loc[:, 'phone_brand']    = te_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "\n",
    "del dtr_events, dval_events\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### No Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 147 ms, sys: 0 ns, total: 147 ms\n",
      "Wall time: 148 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# no events\n",
    "\n",
    "traintest = pd.concat((tr_no_events, te_no_events))\n",
    "ntrain    = len(tr_no_events)\n",
    "\n",
    "del tr_no_events, te_no_events\n",
    "gc.collect();\n",
    "\n",
    "# bag of words for phone brand\n",
    "phone_brand_bow_vec = CountVectorizer()\n",
    "phone_brand_bow     = phone_brand_bow_vec.fit_transform(traintest.phone_brand)\n",
    "\n",
    "# bag of words for device model\n",
    "device_model_bow_vec = CountVectorizer()\n",
    "device_model_bow     = device_model_bow_vec.fit_transform(traintest.device_model)\n",
    "\n",
    "# target encoding\n",
    "traintest.loc[:, 'group'] = pd.factorize(traintest.group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# phone brand (freq)\n",
    "traintest.loc[:, 'phone_brand_freq']  = traintest.groupby('phone_brand')['phone_brand'].transform(lambda x: len(x))\n",
    "\n",
    "# device model (freq)\n",
    "traintest.loc[:, 'device_model_freq'] = traintest.groupby('device_model')['device_model'].transform(lambda x: len(x))\n",
    "\n",
    "# number of different device models for a particular brand\n",
    "num_diff_models = traintest.groupby('phone_brand').apply(lambda x: x['device_model'].nunique())\n",
    "traintest.loc[:, 'num_diff_models'] = traintest.phone_brand.map(num_diff_models)\n",
    "\n",
    "FEATURES = ['phone_brand_freq', \n",
    "            'device_model_freq',\n",
    "            'num_diff_models'\n",
    "           ]\n",
    "\n",
    "y_tr_ne  = traintest.iloc[:ntrain].loc[:, 'group'].values\n",
    "y_val_ne = traintest.iloc[ntrain:].loc[:, 'group'].values\n",
    "\n",
    "traintest = scale(traintest.loc[:, FEATURES].values)\n",
    "\n",
    "X_tr     = sp.sparse.hstack((traintest[:ntrain], \n",
    "                      phone_brand_bow[:ntrain], \n",
    "                      device_model_bow[:ntrain]))\n",
    "\n",
    "X_val    = sp.sparse.hstack((traintest[ntrain:], \n",
    "                      phone_brand_bow[ntrain:], \n",
    "                      device_model_bow[ntrain:]))\n",
    "\n",
    "del traintest\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature set (train) : (8150, 943)\n",
      "Shape of feature set (test) : (2053, 943)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of feature set (train) : {}'.format(X_tr.shape))\n",
    "print('Shape of feature set (test) : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss without events: 2.4145398583119966\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression(C=.02, solver='lbfgs', multi_class='multinomial', n_jobs=-1, random_state=SEED)\n",
    "m.fit(X_tr, y_tr_ne)\n",
    "\n",
    "val_preds_ne = m.predict_proba(X_val)\n",
    "print('Log Loss without events: {}'.format(log_loss(y_val_ne, val_preds_ne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Events"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.3 ms, sys: 12 ms, total: 111 ms\n",
      "Wall time: 111 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# no events\n",
    "\n",
    "traintest = pd.concat((tr_events, te_events))\n",
    "ntrain    = len(tr_events)\n",
    "\n",
    "del tr_events, te_events\n",
    "gc.collect();\n",
    "\n",
    "# bag of words for phone brand\n",
    "phone_brand_bow_vec = CountVectorizer()\n",
    "phone_brand_bow     = phone_brand_bow_vec.fit_transform(traintest.phone_brand)\n",
    "\n",
    "# bag of words for device model\n",
    "device_model_bow_vec = CountVectorizer()\n",
    "device_model_bow     = device_model_bow_vec.fit_transform(traintest.device_model)\n",
    "\n",
    "# encode target\n",
    "traintest.loc[:, 'group']  = pd.factorize(traintest.group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 37s, sys: 1.9 s, total: 3min 39s\n",
      "Wall time: 3min 40s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# phone brand (freq)\n",
    "traintest.loc[:, 'phone_brand_freq']  = traintest.groupby('phone_brand')['phone_brand'].transform(lambda x: len(x))\n",
    "\n",
    "# device model (freq)\n",
    "traintest.loc[:, 'device_model_freq'] = traintest.groupby('device_model')['device_model'].transform(lambda x: len(x))\n",
    "\n",
    "# number of different device models for a particular brand\n",
    "num_diff_models = traintest.groupby('phone_brand').apply(lambda x: x['device_model'].nunique())\n",
    "traintest.loc[:, 'num_diff_models'] = traintest.phone_brand.map(num_diff_models)\n",
    "\n",
    "del num_diff_models\n",
    "gc.collect();\n",
    "\n",
    "# most_generated_event\n",
    "most_generated_event = events.groupby('device_id').apply(lambda x: x['event_id'].value_counts().index.values[0])\n",
    "traintest.loc[:, 'most_generated_event'] = traintest.device_id.map(most_generated_event).fillna(-1)\n",
    "\n",
    "del most_generated_event\n",
    "gc.collect();\n",
    "\n",
    "# hour with most number of events by device\n",
    "hour_with_most_events = events.groupby('device_id')\\\n",
    "                              .apply(lambda x: x['timestamp'].dt.hour.value_counts().index.values[0])\n",
    "\n",
    "\n",
    "traintest.loc[:, 'hour_with_most_events'] = traintest.device_id.map(hour_with_most_events).fillna(0)\n",
    "\n",
    "del hour_with_most_events\n",
    "gc.collect();\n",
    "\n",
    "# number of different hours at which events were generated\n",
    "num_diff_hours = events.groupby('device_id').apply(lambda x: x['timestamp'].dt.hour.nunique())\n",
    "traintest.loc[:, 'num_diff_hours'] = traintest.device_id.map(num_diff_hours).fillna(-1)\n",
    "\n",
    "del num_diff_hours\n",
    "gc.collect();\n",
    "\n",
    "# number of events generated by a device\n",
    "num_events = events.device_id.value_counts()\n",
    "traintest.loc[:, 'num_events'] = traintest.device_id.map(num_events).fillna(0)\n",
    "\n",
    "del num_events\n",
    "gc.collect();\n",
    "\n",
    "# number of different locations from where events were generated by device.\n",
    "num_diff_locations = events.groupby('device_id').apply(lambda x: x.loc[:, ['longitude', 'latitude']].drop_duplicates().shape[0])\n",
    "traintest.loc[:, 'num_diff_locations'] = traintest.device_id.map(num_diff_locations).fillna(-1)\n",
    "\n",
    "del num_diff_locations\n",
    "gc.collect();\n",
    "\n",
    "# number of different applications\n",
    "apps_with_events = traintest.merge(events, on='device_id', how='left')\\\n",
    "                            .merge(app_events, on='event_id', how='left')\n",
    "    \n",
    "num_diff_apps = apps_with_events.groupby('device_id').apply(lambda x: x['app_id'].nunique())\n",
    "traintest.loc[:, 'num_diff_apps'] = traintest.device_id.map(num_diff_apps).fillna(-1)\n",
    "\n",
    "\n",
    "del num_diff_apps, apps_with_events\n",
    "gc.collect();\n",
    "\n",
    "FEATURES = ['phone_brand_freq', \n",
    "            'device_model_freq',\n",
    "            'num_diff_models',\n",
    "            'most_generated_event',\n",
    "            'hour_with_most_events',\n",
    "            'num_events',\n",
    "            'num_diff_hours',\n",
    "            'num_diff_locations',\n",
    "            'num_diff_apps'\n",
    "           ]\n",
    "\n",
    "y_tr_e  = traintest.iloc[:ntrain].loc[:, 'group'].values\n",
    "y_val_e = traintest.iloc[ntrain:].loc[:, 'group'].values\n",
    "\n",
    "traintest = scale(traintest.loc[:, FEATURES].values)\n",
    "\n",
    "X_tr   = sp.sparse.hstack((traintest[:ntrain], \n",
    "                      phone_brand_bow[:ntrain], \n",
    "                      device_model_bow[:ntrain]))\n",
    "\n",
    "X_val   = sp.sparse.hstack((traintest[ntrain:], \n",
    "                      phone_brand_bow[ntrain:], \n",
    "                      device_model_bow[ntrain:]))\n",
    "\n",
    "del traintest\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature set (train) : (3794, 533)\n",
      "Shape of feature set (test) : (933, 533)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of feature set (train) : {}'.format(X_tr.shape))\n",
    "print('Shape of feature set (test) : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss without events: 2.3680449371277104\n"
     ]
    }
   ],
   "source": [
    "m = LogisticRegression(C=.02, solver='lbfgs', multi_class='multinomial', n_jobs=-1, random_state=SEED)\n",
    "m.fit(X_tr, y_tr_e)\n",
    "\n",
    "val_preds_e = m.predict_proba(X_val)\n",
    "print('Log Loss without events: {}'.format(log_loss(y_val_e, val_preds_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.400012141813357"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# combine both devices with no events generated and devices that generated events\n",
    "log_loss(np.hstack((y_val_e, y_val_ne)), np.vstack((val_preds_e, val_preds_ne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Creating separate models for devices that have generated events vs devices that have generated event leads to lower log loss. **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
