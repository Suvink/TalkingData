{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Libraries have been loaded\n"
     ]
    }
   ],
   "source": [
    "__imp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Additional Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import log_loss\n",
    "\n",
    "basepath = os.path.expanduser('~/Desktop/src/ml/talking_data/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 208 ms, sys: 166 ms, total: 374 ms\n",
      "Wall time: 373 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "gender_age_train         = pd.read_feather(os.path.join(basepath, 'data/processed/gender_age_train.feather'))\n",
    "gender_age_test          = pd.read_feather(os.path.join(basepath, 'data/processed/gender_age_test.feather'))\n",
    "label_categories         = pd.read_feather(os.path.join(basepath, 'data/processed/label_categories.feather'))\n",
    "app_labels               = pd.read_feather(os.path.join(basepath, 'data/processed/app_labels.feather'))\n",
    "phone_brand_device_model = pd.read_feather(os.path.join(basepath, 'data/processed/phone_brand_device_model.feather')) \n",
    "app_events               = pd.read_feather(os.path.join(basepath, 'data/processed/app_events.feather'))\n",
    "events                   = pd.read_feather(os.path.join(basepath, 'data/processed/events.feather'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_train_test(gender_age_train):\n",
    "    dtr, dte, _, _ = train_test_split(gender_age_train, \n",
    "                                           gender_age_train.group, \n",
    "                                           stratify=gender_age_train.group,\n",
    "                                           test_size=.2\n",
    "                                          )\n",
    "    \n",
    "    dtr, dval, _, _ = train_test_split(dte, dte.group,\n",
    "                                       stratify=dte.group,\n",
    "                                       test_size=.2\n",
    "                                      )\n",
    "    \n",
    "    del dte\n",
    "    gc.collect()\n",
    "    \n",
    "    return dtr, dval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr, dval = get_train_test(gender_age_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M23-26    0.128600\n",
       "M32-38    0.126926\n",
       "M39+      0.114869\n",
       "M22-      0.100469\n",
       "M29-31    0.097790\n",
       "F33-42    0.074347\n",
       "M27-28    0.073007\n",
       "F23-      0.067649\n",
       "F29-32    0.061956\n",
       "F43+      0.056263\n",
       "F24-26    0.056263\n",
       "F27-28    0.041862\n",
       "Name: group, dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dval.group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "M23-26    0.128695\n",
       "M32-38    0.126936\n",
       "M39+      0.114963\n",
       "M22-      0.100310\n",
       "M29-31    0.097965\n",
       "F33-42    0.074521\n",
       "M27-28    0.072930\n",
       "F23-      0.067655\n",
       "F29-32    0.061961\n",
       "F43+      0.056184\n",
       "F24-26    0.056100\n",
       "F27-28    0.041782\n",
       "Name: group, dtype: float64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtr.group.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: 0.03748520139863991\n",
      "Validation: 0.03720964234150264\n"
     ]
    }
   ],
   "source": [
    "# check number of device with no events in training and test set\n",
    "_ = dtr.merge(events, on='device_id', how='left')\n",
    "print('Train: {}'.format(_[_.event_id.isnull()].shape[0] / len(_)))\n",
    "\n",
    "_ = dval.merge(events, on='device_id', how='left')\n",
    "print('Validation: {}'.format(_[_.event_id.isnull()].shape[0] / len(_)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# dictionary for brand names\n",
    "chinese_to_eng_brands = {\n",
    "'三星'   : 'samsung',\n",
    "'天语'   : 'Ktouch',\n",
    "'海信'   : 'hisense',\n",
    "'联想'   : 'lenovo',\n",
    "'欧比'   : 'obi',\n",
    "'爱派尔' : 'ipair',\n",
    "'努比亚' : 'nubia',\n",
    "'优米'   : 'youmi',\n",
    "'朵唯'   : 'dowe',\n",
    "'黑米'   : 'heymi',\n",
    "'锤子'   : 'hammer',\n",
    "'酷比魔方': 'koobee',\n",
    "'美图'   : 'meitu',\n",
    "'尼比鲁' : 'nibilu',\n",
    "'一加'   : 'oneplus',\n",
    "'优购': 'yougo',\n",
    "'诺基亚': 'nokia',\n",
    "'糖葫芦': 'candy',\n",
    "'中国移动':'ccmc',\n",
    "'语信': 'yuxin',\n",
    "'基伍': 'kiwu',\n",
    "'青橙': 'greeno',\n",
    "'华硕': 'asus',\n",
    "'夏新': 'panosonic',\n",
    "'维图': 'weitu',\n",
    "'艾优尼': 'aiyouni',\n",
    "'摩托罗拉': 'moto',\n",
    "'乡米': 'xiangmi',\n",
    "'米奇': 'micky',\n",
    "'大可乐': 'bigcola',\n",
    "'沃普丰': 'wpf',\n",
    "'神舟': 'hasse',\n",
    "'摩乐': 'mole',\n",
    "'飞秒': 'fs',\n",
    "'米歌': 'mige',\n",
    "'富可视': 'fks',\n",
    "'德赛': 'desci',\n",
    "'梦米': 'mengmi',\n",
    "'乐视': 'lshi',\n",
    "'小杨树':'smallt',\n",
    "'纽曼': 'newman',\n",
    "'邦华' : 'banghua',\n",
    "'E派' : 'epai',\n",
    "'易派': 'epai',\n",
    "'普耐尔': 'pner',\n",
    "'欧新': 'ouxin',\n",
    "'西米': 'ximi',\n",
    "'海尔': 'haier',\n",
    "'波导': 'bodao',\n",
    "'糯米': 'nuomi',\n",
    "'唯米': 'weimi',\n",
    "'酷珀': 'kupo',\n",
    "'谷歌': 'google',\n",
    "'昂达': 'ada',\n",
    "'聆韵': 'lingyun',\n",
    "'华为': 'Huawei',\n",
    "'小米': 'millet',\n",
    "'魅族': 'Meizu',\n",
    "'金立': 'Gionee'\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Traintest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 144 ms, sys: 10.6 ms, total: 154 ms\n",
      "Wall time: 153 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# merge with other data frames\n",
    "tr =  dtr\\\n",
    "        .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "        \n",
    "tr.loc[:, 'phone_brand'] = tr.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "\n",
    "te = dval\\\n",
    "        .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "        \n",
    "te.loc[:, 'phone_brand'] = te.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "\n",
    "traintest = pd.concat((tr, te))\n",
    "ntrain    = len(tr)\n",
    "\n",
    "del tr, te\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 13.3 ms, sys: 3.34 ms, total: 16.7 ms\n",
      "Wall time: 15.6 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "traintest.loc[:, 'phone_brand']  = pd.factorize(traintest.phone_brand)[0]\n",
    "traintest.loc[:, 'device_model'] = pd.factorize(traintest.device_model)[0]\n",
    "\n",
    "# target encoding\n",
    "traintest.loc[:, 'group']        = pd.factorize(traintest.group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 42s, sys: 560 ms, total: 5min 42s\n",
      "Wall time: 5min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# phone brand (freq)\n",
    "traintest.loc[:, 'phone_brand_freq']  = traintest.groupby('phone_brand')['phone_brand'].transform(lambda x: len(x))\n",
    "\n",
    "# device model (freq)\n",
    "traintest.loc[:, 'device_model_freq'] = traintest.groupby('device_model')['device_model'].transform(lambda x: len(x))\n",
    "\n",
    "# number of different device models for a particular brand\n",
    "num_diff_models = traintest.groupby('phone_brand').apply(lambda x: x['device_model'].nunique())\n",
    "traintest.loc[:, 'num_diff_models'] = traintest.phone_brand.map(num_diff_models)\n",
    "\n",
    "# most_generated_event\n",
    "most_generated_event = events.groupby('device_id').apply(lambda x: x['event_id'].value_counts().index.values[0])\n",
    "traintest.loc[:, 'most_generated_event'] = traintest.device_id.map(most_generated_event).fillna(-1)\n",
    "\n",
    "# hour with most number of events by device\n",
    "hour_with_most_events = events.groupby('device_id')\\\n",
    "                              .apply(lambda x: x['timestamp'].dt.hour.value_counts().index.values[0])\n",
    "\n",
    "\n",
    "traintest.loc[:, 'hour_with_most_events'] = traintest.device_id.map(hour_with_most_events).fillna(0)\n",
    "\n",
    "# number of different hours at which events were generated\n",
    "num_diff_hours = events.groupby('device_id').apply(lambda x: x['timestamp'].dt.hour.nunique())\n",
    "traintest.loc[:, 'num_diff_hours'] = traintest.device_id.map(num_diff_hours).fillna(-1)\n",
    "\n",
    "# number of events generated by a device\n",
    "num_events = events.device_id.value_counts()\n",
    "traintest.loc[:, 'num_events'] = traintest.device_id.map(num_events).fillna(0)\n",
    "\n",
    "# number of different locations from where events were generated by device.\n",
    "num_diff_locations = events.groupby('device_id').apply(lambda x: x.loc[:, ['longitude', 'latitude']].drop_duplicates().shape[0])\n",
    "traintest.loc[:, 'num_diff_locations'] = traintest.device_id.map(num_diff_locations).fillna(-1)\n",
    "\n",
    "del num_diff_models, most_generated_event, hour_with_most_events, num_events\n",
    "del num_diff_hours, mean_time_succ_events, num_diff_locations\n",
    "gc.collect();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "FEATURES = ['phone_brand', \n",
    "            'device_model', \n",
    "            'phone_brand_freq', \n",
    "            'device_model_freq',\n",
    "            'num_diff_models',\n",
    "            'most_generated_event',\n",
    "            'hour_with_most_events',\n",
    "            'num_events',\n",
    "            'num_diff_hours',\n",
    "            'num_diff_locations'\n",
    "           ]\n",
    "\n",
    "X_tr = traintest.iloc[:ntrain].loc[:, FEATURES]\n",
    "y_tr = traintest.iloc[:ntrain].loc[:, 'group']\n",
    "\n",
    "X_val = traintest.iloc[ntrain:].loc[:, FEATURES]\n",
    "y_val = traintest.iloc[ntrain:].loc[:, 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature set (train) : (11980, 10)\n",
      "Shape of feature set (test) : (2996, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of feature set (train) : {}'.format(X_tr.shape))\n",
    "print('Shape of feature set (test) : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss: 2.3977648699273484\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_estimators=125, max_depth=6, min_samples_leaf=1, n_jobs=-1, random_state=SEED)\n",
    "m.fit(X_tr, y_tr)\n",
    "\n",
    "val_preds = m.predict_proba(X_val)\n",
    "print('Log Loss: {}'.format(log_loss(y_val, val_preds)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.07535217, 0.11118064, 0.08139042, 0.11180738, 0.14690088,\n",
       "       0.11487609, 0.07286265, 0.11901604, 0.0888724 , 0.07774132])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.feature_importances_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Separate models for devices with no events versus devices with events."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtr_events   = dtr.merge(events, on='device_id', how='left')\\\n",
    "                  .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "    \n",
    "dval_events  = dval.merge(events, on='device_id', how='left')\\\n",
    "                   .merge(phone_brand_device_model, on='device_id', how='left')\n",
    "\n",
    "tr_no_events = dtr_events.loc[dtr_events.event_id.isnull(), :]\n",
    "tr_events    = dtr_events.loc[dtr_events.event_id.notnull(), :]\n",
    "\n",
    "tr_no_events.loc[:, 'phone_brand'] = tr_no_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "tr_events.loc[:, 'phone_brand']    = tr_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "\n",
    "te_no_events = dval_events.loc[dval_events.event_id.isnull(), :]\n",
    "te_events    = dval_events.loc[dval_events.event_id.notnull(), :]\n",
    "\n",
    "te_no_events.loc[:, 'phone_brand'] = te_no_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)\n",
    "te_events.loc[:, 'phone_brand']    = te_events.phone_brand.map(lambda x: chinese_to_eng_brands[x] if x in chinese_to_eng_brands else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 67.6 ms, sys: 12 ms, total: 79.6 ms\n",
      "Wall time: 79 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# no events\n",
    "\n",
    "traintest = pd.concat((tr_no_events, te_no_events))\n",
    "ntrain    = len(tr_no_events)\n",
    "\n",
    "del tr_no_events, te_no_events\n",
    "gc.collect();\n",
    "\n",
    "traintest.loc[:, 'phone_brand']  = pd.factorize(traintest.phone_brand)[0]\n",
    "traintest.loc[:, 'device_model'] = pd.factorize(traintest.device_model)[0]\n",
    "\n",
    "# target encoding\n",
    "traintest.loc[:, 'group']        = pd.factorize(traintest.group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 230 ms, sys: 3 µs, total: 230 ms\n",
      "Wall time: 229 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# phone brand (freq)\n",
    "traintest.loc[:, 'phone_brand_freq']  = traintest.groupby('phone_brand')['phone_brand'].transform(lambda x: len(x))\n",
    "\n",
    "# device model (freq)\n",
    "traintest.loc[:, 'device_model_freq'] = traintest.groupby('device_model')['device_model'].transform(lambda x: len(x))\n",
    "\n",
    "# number of different device models for a particular brand\n",
    "num_diff_models = traintest.groupby('phone_brand').apply(lambda x: x['device_model'].nunique())\n",
    "traintest.loc[:, 'num_diff_models'] = traintest.phone_brand.map(num_diff_models)\n",
    "\n",
    "FEATURES = ['phone_brand', \n",
    "            'device_model', \n",
    "            'phone_brand_freq', \n",
    "            'device_model_freq',\n",
    "            'num_diff_models'\n",
    "           ]\n",
    "\n",
    "X_tr     = traintest.iloc[:ntrain].loc[:, FEATURES]\n",
    "y_tr_ne  = traintest.iloc[:ntrain].loc[:, 'group']\n",
    "\n",
    "X_val    = traintest.iloc[ntrain:].loc[:, FEATURES]\n",
    "y_val_ne = traintest.iloc[ntrain:].loc[:, 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature set (train) : (8190, 5)\n",
      "Shape of feature set (test) : (2038, 5)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of feature set (train) : {}'.format(X_tr.shape))\n",
    "print('Shape of feature set (test) : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss without events: 2.4130237681482973\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_estimators=125, max_depth=3, min_samples_leaf=1, n_jobs=-1, random_state=SEED)\n",
    "m.fit(X_tr, y_tr_ne)\n",
    "\n",
    "val_preds_ne = m.predict_proba(X_val)\n",
    "print('Log Loss without events: {}'.format(log_loss(y_val_ne, val_preds_ne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 145 ms, sys: 3.99 ms, total: 149 ms\n",
      "Wall time: 147 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# no events\n",
    "\n",
    "traintest = pd.concat((tr_events, te_events))\n",
    "ntrain    = len(tr_events)\n",
    "\n",
    "del tr_events, te_events\n",
    "gc.collect();\n",
    "\n",
    "traintest.loc[:, 'phone_brand']  = pd.factorize(traintest.phone_brand)[0]\n",
    "traintest.loc[:, 'device_model'] = pd.factorize(traintest.device_model)[0]\n",
    "\n",
    "# target encoding\n",
    "traintest.loc[:, 'group']        = pd.factorize(traintest.group)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 4s, sys: 312 ms, total: 3min 5s\n",
      "Wall time: 3min 5s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# phone brand (freq)\n",
    "traintest.loc[:, 'phone_brand_freq']  = traintest.groupby('phone_brand')['phone_brand'].transform(lambda x: len(x))\n",
    "\n",
    "# device model (freq)\n",
    "traintest.loc[:, 'device_model_freq'] = traintest.groupby('device_model')['device_model'].transform(lambda x: len(x))\n",
    "\n",
    "# number of different device models for a particular brand\n",
    "num_diff_models = traintest.groupby('phone_brand').apply(lambda x: x['device_model'].nunique())\n",
    "traintest.loc[:, 'num_diff_models'] = traintest.phone_brand.map(num_diff_models)\n",
    "\n",
    "# most_generated_event\n",
    "most_generated_event = events.groupby('device_id').apply(lambda x: x['event_id'].value_counts().index.values[0])\n",
    "traintest.loc[:, 'most_generated_event'] = traintest.device_id.map(most_generated_event).fillna(-1)\n",
    "\n",
    "# hour with most number of events by device\n",
    "hour_with_most_events = events.groupby('device_id')\\\n",
    "                              .apply(lambda x: x['timestamp'].dt.hour.value_counts().index.values[0])\n",
    "\n",
    "\n",
    "traintest.loc[:, 'hour_with_most_events'] = traintest.device_id.map(hour_with_most_events).fillna(0)\n",
    "\n",
    "# number of different hours at which events were generated\n",
    "num_diff_hours = events.groupby('device_id').apply(lambda x: x['timestamp'].dt.hour.nunique())\n",
    "traintest.loc[:, 'num_diff_hours'] = traintest.device_id.map(num_diff_hours).fillna(-1)\n",
    "\n",
    "# number of events generated by a device\n",
    "num_events = events.device_id.value_counts()\n",
    "traintest.loc[:, 'num_events'] = traintest.device_id.map(num_events).fillna(0)\n",
    "\n",
    "# number of different locations from where events were generated by device.\n",
    "num_diff_locations = events.groupby('device_id').apply(lambda x: x.loc[:, ['longitude', 'latitude']].drop_duplicates().shape[0])\n",
    "traintest.loc[:, 'num_diff_locations'] = traintest.device_id.map(num_diff_locations).fillna(-1)\n",
    "\n",
    "del num_diff_models, most_generated_event, hour_with_most_events, num_events\n",
    "del num_diff_hours, num_diff_locations\n",
    "gc.collect();\n",
    "\n",
    "FEATURES = ['phone_brand', \n",
    "            'device_model', \n",
    "            'phone_brand_freq', \n",
    "            'device_model_freq',\n",
    "            'num_diff_models',\n",
    "            'most_generated_event',\n",
    "            'hour_with_most_events',\n",
    "            'num_events',\n",
    "            'num_diff_hours',\n",
    "            'num_diff_locations'\n",
    "           ]\n",
    "\n",
    "X_tr   = traintest.iloc[:ntrain].loc[:, FEATURES]\n",
    "y_tr_e = traintest.iloc[:ntrain].loc[:, 'group']\n",
    "\n",
    "X_val   = traintest.iloc[ntrain:].loc[:, FEATURES]\n",
    "y_val_e = traintest.iloc[ntrain:].loc[:, 'group']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of feature set (train) : (211737, 10)\n",
      "Shape of feature set (test) : (53079, 10)\n"
     ]
    }
   ],
   "source": [
    "print('Shape of feature set (train) : {}'.format(X_tr.shape))\n",
    "print('Shape of feature set (test) : {}'.format(X_val.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Log Loss without events: 2.3524177642694517\n"
     ]
    }
   ],
   "source": [
    "m = RandomForestClassifier(n_estimators=125, max_depth=3, min_samples_leaf=1, n_jobs=-1, random_state=SEED)\n",
    "m.fit(X_tr, y_tr_e)\n",
    "\n",
    "val_preds_e = m.predict_proba(X_val)\n",
    "print('Log Loss without events: {}'.format(log_loss(y_val_e, val_preds_e)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2.3546587250602258"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(np.hstack((y_val_e.values, y_val_ne.values)), np.vstack((val_preds_e, val_preds_ne)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Creating separate models for devices that have generated events vs devices that have generated event leads to lower log loss. **"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
